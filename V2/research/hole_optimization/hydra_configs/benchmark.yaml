# Benchmark configuration for comparing optimizers
# Usage: python main.py --config-name=benchmark

# Set mode to benchmark
mode: "benchmark"

# Benchmark settings
benchmark:
  # Which optimizers to compare
  optimizers:
    - "differentiable"
    # Uncomment when other optimizers are implemented:
    # - "genetic_algorithm"
    # - "simulated_annealing"

  # Number of runs per optimizer (for statistical significance)
  num_runs: 3

  # Timeout per run (seconds)
  timeout: 1800 # 30 minutes

  # Run in parallel (much faster)
  parallel: true

# Base experiment configuration (shared across all optimizers)
optimizer_type: "differentiable" # Will be overridden for each optimizer
random_seed: 42
verbose: true
create_plots: true

# Physical constraints (same for all optimizers)
constraints:
  vertical_length: 20.0
  handle_length: 38.0
  forearm_length: 17.0

  vertical_pivot_length: 19.0
  forearm_pivot_length: 19.0

  min_hole_distance: 2.0
  hole_margin: 0.5

  alpha_min: 85.0
  alpha_max: 115.0
  beta_min: 95.0
  beta_max: 140.0
  gamma_min: -9.0
  gamma_max: 9.0

  require_alpha_beta_sum_ge_180: true

# Optimization objectives (same for all optimizers)
objectives:
  vocabulary_weight: 1.0
  truss_complexity_weight: 0.5
  manufacturability_weight: 0.1
  robustness_weight: 0.1

  max_unique_trusses: 15
  min_vocabulary_size: 50

  length_tolerance: 0.25
  angle_tolerance: 1.0

# Optimizer-specific configurations
# (Reduced iterations for faster benchmarking)
differentiable:
  learning_rate: 0.01
  max_iterations: 200 # Reduced for benchmark
  convergence_threshold: 0.000001

  temperature: 0.1
  temperature_schedule: "constant"

  hidden_dims: [64, 32]
  activation: "relu"

  l2_reg: 0.0001
  dropout_rate: 0.1

genetic_algorithm:
  population_size: 50 # Reduced for benchmark
  num_generations: 100 # Reduced for benchmark
  crossover_rate: 0.8
  mutation_rate: 0.1

  selection_method: "tournament"
  tournament_size: 3

  use_nsga2: true
  crowding_distance_weight: 0.1

simulated_annealing:
  initial_temperature: 100.0
  final_temperature: 0.01
  max_iterations: 1000 # Reduced for benchmark

  cooling_schedule: "exponential"
  cooling_rate: 0.95

  perturbation_strength: 0.1
  adaptive_perturbation: true
